{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framingham_CHD_preprocessed_data\n",
    "https://www.kaggle.com/datasets/captainozlem/framingham-chd-preprocessed-data 에서 가져온 데이터입니다.\n",
    "\n",
    "Demographic:\n",
    "• Sex: male or female(Nominal)\n",
    "• Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
    "\n",
    "Behavioral\n",
    "• Education: 0: Less than High School and High School degrees, 1: College Degree and Higher\n",
    "• Current Smoker: whether or not the patient is a current smoker (Nominal)\n",
    "• Cigs Per Day: the number of cigarettes that the person smoked on average in one day. (can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
    "\n",
    "Medical(history)\n",
    "• BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n",
    "• Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n",
    "• Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n",
    "• Diabetes: whether or not the patient had diabetes (Nominal)\n",
    "\n",
    "Medical(current)\n",
    "• Tot Chol: total cholesterol level (Continuous)\n",
    "• Sys BP: systolic blood pressure (Continuous)\n",
    "• Dia BP: diastolic blood pressure (Continuous)\n",
    "• BMI: Body Mass Index (Continuous)\n",
    "• Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
    "• Glucose: glucose level (Continuous)\n",
    "\n",
    "Predict variable (desired target)\n",
    "• 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"여러분이 풀고자 하는 문제를 잘 설정하였는가?\"\n",
    "- Framingham_CHD_preprocessed_data는 10년간의 심장병 가능성 혹은 병증 존재 여부를 타겟으로 15가지의 특성을 고려합니다. 15가지 항목값을 인풋하면 10년안에 심장병이 올 가능성에 대해 진단을 해주는 간략한 프로그램을 만든다고 보시면되겠습니다. 이것이 명목상의 개발 근거이나, 실제로는 xgboost와 딥러닝 간의 성능차이, 신경망 노드수와 레이어 간의 차이를 알아보고자 작성하였습니다. xgboost estimator 2000과, 90 * 1레이어, 45 * 2레이어, 30 * 3레이어 각 에폭 20 간의 차이를 분석할 것입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. \"문제를 풀기 위한 모델 선택을 알맞게 설정하였는가?\"\n",
    "- 15개 정도의 특성을 다루는 간단한 xgboost머신러닝 모델 혹은 간단한 신경망 구조입니다. 문제 자체가 많은 변수를 다루지 않아 nlp나 cv처럼 복잡한 모델이 들어갈 수 없었습니다. 다만 최대한 튀는 값을 줄이기 위해 stratified한 데이터셋으로 모델을 사용하였습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. \"모델 학습을 제대로 진행하였는가?\"\n",
    "- 전처리가 거의 되어있는 데이터셋으로 진행하였기 때문에 특별히 할게 없었습니다. 패러미터는 일반적으로 넣는 값에서 조금 정교하거나 혹은 과적합이 일어날 수 있는 값을 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4133 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39          1              0         0.0     0.0   \n",
       "1        0   46          0              0         0.0     0.0   \n",
       "2        1   48          0              1        20.0     0.0   \n",
       "3        0   61          1              1        30.0     0.0   \n",
       "4        0   46          1              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4128     1   50          0              1         1.0     0.0   \n",
       "4129     1   51          1              1        43.0     0.0   \n",
       "4130     0   48          0              1        20.0     0.0   \n",
       "4131     0   44          0              1        15.0     0.0   \n",
       "4132     0   52          0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4128                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4129                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4130                0             0         0    248.0  131.0   72.0  22.00   \n",
       "4131                0             0         0    210.0  126.5   87.0  19.16   \n",
       "4132                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4128       66.0     86.0           1  \n",
       "4129       65.0     68.0           0  \n",
       "4130       84.0     86.0           0  \n",
       "4131       86.0     82.0           0  \n",
       "4132       80.0    107.0           0  \n",
       "\n",
       "[4133 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin = pd.read_csv('data/CHD_preprocessed.csv')\n",
    "df_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3505\n",
       "1     628\n",
       "Name: TenYearCHD, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'TenYearCHD'\n",
    "df_origin[target].value_counts()\n",
    "#85대 15비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin.isna().any(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.007896</td>\n",
       "      <td>-0.083624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009661</td>\n",
       "      <td>-0.012143</td>\n",
       "      <td>-0.018426</td>\n",
       "      <td>-0.027600</td>\n",
       "      <td>-0.053647</td>\n",
       "      <td>-0.026187</td>\n",
       "      <td>-0.009107</td>\n",
       "      <td>-0.098666</td>\n",
       "      <td>-0.050535</td>\n",
       "      <td>-0.106785</td>\n",
       "      <td>-0.057869</td>\n",
       "      <td>-0.023268</td>\n",
       "      <td>-0.027642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentSmoker</th>\n",
       "      <td>0.186474</td>\n",
       "      <td>-0.209292</td>\n",
       "      <td>-0.009661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772066</td>\n",
       "      <td>-0.058672</td>\n",
       "      <td>-0.040169</td>\n",
       "      <td>-0.106239</td>\n",
       "      <td>-0.041377</td>\n",
       "      <td>-0.066791</td>\n",
       "      <td>-0.129491</td>\n",
       "      <td>-0.112964</td>\n",
       "      <td>-0.171327</td>\n",
       "      <td>0.054301</td>\n",
       "      <td>-0.051770</td>\n",
       "      <td>0.012119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartRate</th>\n",
       "      <td>-0.115695</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>-0.057869</td>\n",
       "      <td>0.054301</td>\n",
       "      <td>0.064937</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>0.158807</td>\n",
       "      <td>0.058111</td>\n",
       "      <td>0.096653</td>\n",
       "      <td>0.194802</td>\n",
       "      <td>0.184715</td>\n",
       "      <td>0.078611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098234</td>\n",
       "      <td>0.030611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigsPerDay</th>\n",
       "      <td>0.319310</td>\n",
       "      <td>-0.198508</td>\n",
       "      <td>-0.012143</td>\n",
       "      <td>0.772066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051642</td>\n",
       "      <td>-0.037350</td>\n",
       "      <td>-0.069791</td>\n",
       "      <td>-0.028973</td>\n",
       "      <td>-0.048612</td>\n",
       "      <td>-0.090185</td>\n",
       "      <td>-0.059215</td>\n",
       "      <td>-0.094155</td>\n",
       "      <td>0.064937</td>\n",
       "      <td>-0.042214</td>\n",
       "      <td>0.049752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.062772</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>-0.106785</td>\n",
       "      <td>-0.171327</td>\n",
       "      <td>-0.094155</td>\n",
       "      <td>0.101606</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.304564</td>\n",
       "      <td>0.088939</td>\n",
       "      <td>0.104773</td>\n",
       "      <td>0.329173</td>\n",
       "      <td>0.382789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078611</td>\n",
       "      <td>0.083245</td>\n",
       "      <td>0.056034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentStroke</th>\n",
       "      <td>-0.005761</td>\n",
       "      <td>0.057653</td>\n",
       "      <td>-0.027600</td>\n",
       "      <td>-0.040169</td>\n",
       "      <td>-0.037350</td>\n",
       "      <td>0.098119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>0.013515</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.060080</td>\n",
       "      <td>0.045852</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>0.030347</td>\n",
       "      <td>0.071780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totChol</th>\n",
       "      <td>-0.092347</td>\n",
       "      <td>0.260863</td>\n",
       "      <td>-0.009107</td>\n",
       "      <td>-0.066791</td>\n",
       "      <td>-0.048612</td>\n",
       "      <td>0.079875</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.172660</td>\n",
       "      <td>0.045837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220514</td>\n",
       "      <td>0.171262</td>\n",
       "      <td>0.104773</td>\n",
       "      <td>0.096653</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.076073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.018395</td>\n",
       "      <td>0.099897</td>\n",
       "      <td>-0.026187</td>\n",
       "      <td>-0.041377</td>\n",
       "      <td>-0.028973</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.013515</td>\n",
       "      <td>0.074180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045837</td>\n",
       "      <td>0.117363</td>\n",
       "      <td>0.055491</td>\n",
       "      <td>0.088939</td>\n",
       "      <td>0.058111</td>\n",
       "      <td>0.602840</td>\n",
       "      <td>0.077874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031608</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.186474</td>\n",
       "      <td>0.319310</td>\n",
       "      <td>-0.057233</td>\n",
       "      <td>-0.005761</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>-0.092347</td>\n",
       "      <td>-0.045904</td>\n",
       "      <td>0.045710</td>\n",
       "      <td>0.062772</td>\n",
       "      <td>-0.115695</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.082536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.119449</td>\n",
       "      <td>-0.023268</td>\n",
       "      <td>-0.051770</td>\n",
       "      <td>-0.042214</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>0.030347</td>\n",
       "      <td>0.086972</td>\n",
       "      <td>0.602840</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.143515</td>\n",
       "      <td>0.067892</td>\n",
       "      <td>0.083245</td>\n",
       "      <td>0.098234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMeds</th>\n",
       "      <td>-0.057233</td>\n",
       "      <td>0.139774</td>\n",
       "      <td>-0.018426</td>\n",
       "      <td>-0.058672</td>\n",
       "      <td>-0.051642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098119</td>\n",
       "      <td>0.270598</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.079875</td>\n",
       "      <td>0.266320</td>\n",
       "      <td>0.207627</td>\n",
       "      <td>0.101606</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>0.108272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaBP</th>\n",
       "      <td>0.045710</td>\n",
       "      <td>0.214161</td>\n",
       "      <td>-0.050535</td>\n",
       "      <td>-0.112964</td>\n",
       "      <td>-0.059215</td>\n",
       "      <td>0.207627</td>\n",
       "      <td>0.045852</td>\n",
       "      <td>0.623534</td>\n",
       "      <td>0.055491</td>\n",
       "      <td>0.171262</td>\n",
       "      <td>0.791446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382789</td>\n",
       "      <td>0.184715</td>\n",
       "      <td>0.067892</td>\n",
       "      <td>0.157134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentHyp</th>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.311652</td>\n",
       "      <td>-0.053647</td>\n",
       "      <td>-0.106239</td>\n",
       "      <td>-0.069791</td>\n",
       "      <td>0.270598</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074180</td>\n",
       "      <td>0.172660</td>\n",
       "      <td>0.700479</td>\n",
       "      <td>0.623534</td>\n",
       "      <td>0.304564</td>\n",
       "      <td>0.158807</td>\n",
       "      <td>0.086972</td>\n",
       "      <td>0.190151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.031608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083624</td>\n",
       "      <td>-0.209292</td>\n",
       "      <td>-0.198508</td>\n",
       "      <td>0.139774</td>\n",
       "      <td>0.057653</td>\n",
       "      <td>0.311652</td>\n",
       "      <td>0.099897</td>\n",
       "      <td>0.260863</td>\n",
       "      <td>0.400731</td>\n",
       "      <td>0.214161</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.119449</td>\n",
       "      <td>0.219590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysBP</th>\n",
       "      <td>-0.045904</td>\n",
       "      <td>0.400731</td>\n",
       "      <td>-0.098666</td>\n",
       "      <td>-0.129491</td>\n",
       "      <td>-0.090185</td>\n",
       "      <td>0.266320</td>\n",
       "      <td>0.060080</td>\n",
       "      <td>0.700479</td>\n",
       "      <td>0.117363</td>\n",
       "      <td>0.220514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791446</td>\n",
       "      <td>0.329173</td>\n",
       "      <td>0.194802</td>\n",
       "      <td>0.143515</td>\n",
       "      <td>0.224514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TenYearCHD</th>\n",
       "      <td>0.082536</td>\n",
       "      <td>0.219590</td>\n",
       "      <td>-0.027642</td>\n",
       "      <td>0.012119</td>\n",
       "      <td>0.049752</td>\n",
       "      <td>0.108272</td>\n",
       "      <td>0.071780</td>\n",
       "      <td>0.190151</td>\n",
       "      <td>0.077874</td>\n",
       "      <td>0.076073</td>\n",
       "      <td>0.224514</td>\n",
       "      <td>0.157134</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.030611</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     male       age  education  currentSmoker  cigsPerDay  \\\n",
       "education        0.007896 -0.083624   1.000000      -0.009661   -0.012143   \n",
       "currentSmoker    0.186474 -0.209292  -0.009661       1.000000    0.772066   \n",
       "heartRate       -0.115695  0.003339  -0.057869       0.054301    0.064937   \n",
       "cigsPerDay       0.319310 -0.198508  -0.012143       0.772066    1.000000   \n",
       "BMI              0.062772  0.136667  -0.106785      -0.171327   -0.094155   \n",
       "prevalentStroke -0.005761  0.057653  -0.027600      -0.040169   -0.037350   \n",
       "totChol         -0.092347  0.260863  -0.009107      -0.066791   -0.048612   \n",
       "diabetes         0.018395  0.099897  -0.026187      -0.041377   -0.028973   \n",
       "male             1.000000 -0.031608   0.007896       0.186474    0.319310   \n",
       "glucose          0.003568  0.119449  -0.023268      -0.051770   -0.042214   \n",
       "BPMeds          -0.057233  0.139774  -0.018426      -0.058672   -0.051642   \n",
       "diaBP            0.045710  0.214161  -0.050535      -0.112964   -0.059215   \n",
       "prevalentHyp    -0.000075  0.311652  -0.053647      -0.106239   -0.069791   \n",
       "age             -0.031608  1.000000  -0.083624      -0.209292   -0.198508   \n",
       "sysBP           -0.045904  0.400731  -0.098666      -0.129491   -0.090185   \n",
       "TenYearCHD       0.082536  0.219590  -0.027642       0.012119    0.049752   \n",
       "\n",
       "                   BPMeds  prevalentStroke  prevalentHyp  diabetes   totChol  \\\n",
       "education       -0.018426        -0.027600     -0.053647 -0.026187 -0.009107   \n",
       "currentSmoker   -0.058672        -0.040169     -0.106239 -0.041377 -0.066791   \n",
       "heartRate        0.031348        -0.007438      0.158807  0.058111  0.096653   \n",
       "cigsPerDay      -0.051642        -0.037350     -0.069791 -0.028973 -0.048612   \n",
       "BMI              0.101606         0.019130      0.304564  0.088939  0.104773   \n",
       "prevalentStroke  0.098119         1.000000      0.064113  0.013515  0.002617   \n",
       "totChol          0.079875         0.002617      0.172660  0.045837  1.000000   \n",
       "diabetes         0.040979         0.013515      0.074180  1.000000  0.045837   \n",
       "male            -0.057233        -0.005761     -0.000075  0.018395 -0.092347   \n",
       "glucose          0.049444         0.030347      0.086972  0.602840  0.055400   \n",
       "BPMeds           1.000000         0.098119      0.270598  0.040979  0.079875   \n",
       "diaBP            0.207627         0.045852      0.623534  0.055491  0.171262   \n",
       "prevalentHyp     0.270598         0.064113      1.000000  0.074180  0.172660   \n",
       "age              0.139774         0.057653      0.311652  0.099897  0.260863   \n",
       "sysBP            0.266320         0.060080      0.700479  0.117363  0.220514   \n",
       "TenYearCHD       0.108272         0.071780      0.190151  0.077874  0.076073   \n",
       "\n",
       "                    sysBP     diaBP       BMI  heartRate   glucose  TenYearCHD  \n",
       "education       -0.098666 -0.050535 -0.106785  -0.057869 -0.023268   -0.027642  \n",
       "currentSmoker   -0.129491 -0.112964 -0.171327   0.054301 -0.051770    0.012119  \n",
       "heartRate        0.194802  0.184715  0.078611   1.000000  0.098234    0.030611  \n",
       "cigsPerDay      -0.090185 -0.059215 -0.094155   0.064937 -0.042214    0.049752  \n",
       "BMI              0.329173  0.382789  1.000000   0.078611  0.083245    0.056034  \n",
       "prevalentStroke  0.060080  0.045852  0.019130  -0.007438  0.030347    0.071780  \n",
       "totChol          0.220514  0.171262  0.104773   0.096653  0.055400    0.076073  \n",
       "diabetes         0.117363  0.055491  0.088939   0.058111  0.602840    0.077874  \n",
       "male            -0.045904  0.045710  0.062772  -0.115695  0.003568    0.082536  \n",
       "glucose          0.143515  0.067892  0.083245   0.098234  1.000000    0.105028  \n",
       "BPMeds           0.266320  0.207627  0.101606   0.031348  0.049444    0.108272  \n",
       "diaBP            0.791446  1.000000  0.382789   0.184715  0.067892    0.157134  \n",
       "prevalentHyp     0.700479  0.623534  0.304564   0.158807  0.086972    0.190151  \n",
       "age              0.400731  0.214161  0.136667   0.003339  0.119449    0.219590  \n",
       "sysBP            1.000000  0.791446  0.329173   0.194802  0.143515    0.224514  \n",
       "TenYearCHD       0.224514  0.157134  0.056034   0.030611  0.105028    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#상관계수를 알아보고 가설을 세우기 전에 일단 (train, val)[이상 nonTest], test 셋으로 나눕니다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_nonTest, df_test = train_test_split(df_origin, test_size= 0.2, random_state=42, stratify=df_origin[target])\n",
    "df_nonTest.corr().sort_values(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=target)\n",
    "y_test = df_test[target]\n",
    "X_nonTest = df_nonTest.drop(columns=target)\n",
    "y_nonTest = df_nonTest[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 started...\n",
      "[0]\tvalidation_0-auc:0.65000\n",
      "[100]\tvalidation_0-auc:0.60726\n",
      "Batch 1 started...\n",
      "[0]\tvalidation_0-auc:0.67783\n",
      "[112]\tvalidation_0-auc:0.64306\n",
      "Batch 2 started...\n",
      "[0]\tvalidation_0-auc:0.72174\n",
      "[175]\tvalidation_0-auc:0.70078\n",
      "Batch 3 started...\n",
      "[0]\tvalidation_0-auc:0.62637\n",
      "[118]\tvalidation_0-auc:0.60996\n",
      "Batch 4 started...\n",
      "[0]\tvalidation_0-auc:0.66268\n",
      "[99]\tvalidation_0-auc:0.60098\n",
      "Batch 5 started...\n",
      "[0]\tvalidation_0-auc:0.64142\n",
      "[100]\tvalidation_0-auc:0.60553\n",
      "Batch 6 started...\n",
      "[0]\tvalidation_0-auc:0.63468\n",
      "[104]\tvalidation_0-auc:0.61779\n",
      "Batch 7 started...\n",
      "[0]\tvalidation_0-auc:0.63232\n",
      "[123]\tvalidation_0-auc:0.58971\n",
      "Batch 8 started...\n",
      "[0]\tvalidation_0-auc:0.68436\n",
      "[102]\tvalidation_0-auc:0.65164\n",
      "Batch 9 started...\n",
      "[0]\tvalidation_0-auc:0.68146\n",
      "[100]\tvalidation_0-auc:0.62236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "kfold = 10\n",
    "\n",
    "folds = StratifiedKFold(n_splits=kfold)\n",
    "\n",
    "val = np.zeros(X_nonTest.shape[0])\n",
    "models = []\n",
    "for fold_index, (train_index, val_index) in enumerate(folds.split(X_nonTest,y_nonTest)):\n",
    "    print('Batch {} started...'.format(fold_index))\n",
    "    gc.collect()\n",
    "\n",
    "    model_xgb =  xgb.XGBClassifier(max_depth=5,\n",
    "                              n_estimators=2000,\n",
    "                              learning_rate=0.2,\n",
    "                              objective='binary:logistic', \n",
    "                              verbosity =1,\n",
    "                              eval_metric  = 'auc',\n",
    "                              tree_method='gpu_hist',\n",
    "                              n_jobs=3,\n",
    "                              enable_categorical=True,\n",
    "                              early_stopping_rounds= 100\n",
    "                              )\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_nonTest.iloc[train_index]\n",
    "    )\n",
    "\n",
    "    bst = model_xgb.fit(X_nonTest.iloc[train_index],y_nonTest.iloc[train_index],\n",
    "              eval_set = [(X_nonTest.iloc[val_index],y_nonTest.iloc[val_index])],\n",
    "              verbose= 200,\n",
    "              sample_weight= classes_weights\n",
    "              )\n",
    "    models.append(model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.90      0.82       593\n",
      "        True       0.52      0.28      0.37       234\n",
      "\n",
      "    accuracy                           0.72       827\n",
      "   macro avg       0.64      0.59      0.60       827\n",
      "weighted avg       0.69      0.72      0.69       827\n",
      "\n",
      "0.5904354218013577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred = np.zeros(df_test.shape[0])\n",
    "for model in models:\n",
    "    pred += model.predict_proba(df_test.drop(columns=target))[:,1]/folds.n_splits\n",
    "df_pred = pd.DataFrame(pred, columns = [target])\n",
    "print(classification_report(pred > 0.5, df_test[target]))\n",
    "auc_score_b = roc_auc_score(pred > 0.5, df_test[target])\n",
    "print(auc_score_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import EarlyStopping\n",
    "#시드 고정\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 제외 총 특성 수의 6배 하여(15 * 6) model을 만듭니다.\n",
    "def create_model1():\n",
    "    model_deep = Sequential()\n",
    "    model_deep.add(Dense(15 * 6, activation='relu'))\n",
    "    model_deep.add(Dense(1, activation='sigmoid'))\n",
    "    model_deep.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[AUC()])\n",
    "    return model_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 started...\n",
      "Epoch 1/20\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 4.1396 - auc: 0.4860WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 2s 17ms/step - loss: 3.9596 - auc: 0.4796 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.1673 - auc: 0.5487 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8410 - auc: 0.6181 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7752 - auc: 0.6360 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7731 - auc: 0.6341 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7151 - auc: 0.6489 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6927 - auc: 0.6646 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6923 - auc: 0.6623 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7489 - auc: 0.6261 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7426 - auc: 0.6460 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6778 - auc: 0.6722 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6826 - auc: 0.6719 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6669 - auc: 0.6735 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6447 - auc: 0.6972 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7154 - auc: 0.6565 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6615 - auc: 0.6751 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6788 - auc: 0.6656 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7554 - auc: 0.6425 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6553 - auc: 0.6869 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6353 - auc: 0.7007 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Batch 1 started...\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.1164 - auc_1: 0.4948WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 16ms/step - loss: 1.1164 - auc_1: 0.4948 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8237 - auc_1: 0.5844 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7462 - auc_1: 0.6168 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.7342 - auc_1: 0.6221 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6874 - auc_1: 0.6521 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7018 - auc_1: 0.6327 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6984 - auc_1: 0.6475 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6939 - auc_1: 0.6438 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7206 - auc_1: 0.6222 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6773 - auc_1: 0.6599 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6769 - auc_1: 0.6661 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6891 - auc_1: 0.6708 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6576 - auc_1: 0.6775 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6588 - auc_1: 0.6706 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6705 - auc_1: 0.6715 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6454 - auc_1: 0.6860 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6482 - auc_1: 0.6804 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6672 - auc_1: 0.6695 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6626 - auc_1: 0.6698 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6393 - auc_1: 0.6930 - val_loss: 0.0000e+00 - val_auc_1: 0.0000e+00\n",
      "Batch 2 started...\n",
      "Epoch 1/20\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 2.1329 - auc_2: 0.5619WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 16ms/step - loss: 2.0110 - auc_2: 0.5645 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1975 - auc_2: 0.6154 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9695 - auc_2: 0.5909 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.8713 - auc_2: 0.5929 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7705 - auc_2: 0.6023 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6954 - auc_2: 0.6222 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6866 - auc_2: 0.6411 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6980 - auc_2: 0.6391 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7335 - auc_2: 0.6303 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7528 - auc_2: 0.6296 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6916 - auc_2: 0.6592 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6649 - auc_2: 0.6780 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6556 - auc_2: 0.6763 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6760 - auc_2: 0.6558 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6783 - auc_2: 0.6522 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6548 - auc_2: 0.6760 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6632 - auc_2: 0.6644 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6763 - auc_2: 0.6654 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6841 - auc_2: 0.6578 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6545 - auc_2: 0.6773 - val_loss: 0.0000e+00 - val_auc_2: 0.0000e+00\n",
      "Batch 3 started...\n",
      "Epoch 1/20\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 15.6602 - auc_3: 0.4888WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 13.8548 - auc_3: 0.4999 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.1385 - auc_3: 0.5323 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.3393 - auc_3: 0.5415 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.0670 - auc_3: 0.5226 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8917 - auc_3: 0.5308 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.7792 - auc_3: 0.5558 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7332 - auc_3: 0.5858 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7235 - auc_3: 0.5899 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7432 - auc_3: 0.6089 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7205 - auc_3: 0.6254 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7415 - auc_3: 0.6180 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6641 - auc_3: 0.6688 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6542 - auc_3: 0.6689 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7002 - auc_3: 0.6324 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6528 - auc_3: 0.6743 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6470 - auc_3: 0.6770 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6536 - auc_3: 0.6724 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6507 - auc_3: 0.6807 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7322 - auc_3: 0.6229 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6683 - auc_3: 0.6719 - val_loss: 0.0000e+00 - val_auc_3: 0.0000e+00\n",
      "Batch 4 started...\n",
      "Epoch 1/20\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 15.0867 - auc_4: 0.4945WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 15.0024 - auc_4: 0.4943 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.3775 - auc_4: 0.4644 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.1493 - auc_4: 0.4965 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.8224 - auc_4: 0.5679 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.7601 - auc_4: 0.5772 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7206 - auc_4: 0.6140 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6927 - auc_4: 0.6409 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6853 - auc_4: 0.6337 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7384 - auc_4: 0.6128 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7332 - auc_4: 0.6200 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7113 - auc_4: 0.6242 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6861 - auc_4: 0.6607 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6879 - auc_4: 0.6534 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6856 - auc_4: 0.6457 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6898 - auc_4: 0.6402 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6858 - auc_4: 0.6509 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6534 - auc_4: 0.6702 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6692 - auc_4: 0.6631 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6741 - auc_4: 0.6546 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6379 - auc_4: 0.6905 - val_loss: 0.0000e+00 - val_auc_4: 0.0000e+00\n",
      "Batch 5 started...\n",
      "Epoch 1/20\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 24.5509 - auc_5: 0.4954WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 14ms/step - loss: 23.5482 - auc_5: 0.5021 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 3.3089 - auc_5: 0.5369 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.2818 - auc_5: 0.5495 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7764 - auc_5: 0.6112 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7118 - auc_5: 0.6229 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6857 - auc_5: 0.6548 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6641 - auc_5: 0.6651 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6679 - auc_5: 0.6509 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6890 - auc_5: 0.6433 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6918 - auc_5: 0.6431 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6912 - auc_5: 0.6433 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6799 - auc_5: 0.6611 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6808 - auc_5: 0.6603 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7081 - auc_5: 0.6369 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7108 - auc_5: 0.6324 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6754 - auc_5: 0.6614 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6375 - auc_5: 0.6908 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6429 - auc_5: 0.6844 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6692 - auc_5: 0.6570 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6448 - auc_5: 0.6838 - val_loss: 0.0000e+00 - val_auc_5: 0.0000e+00\n",
      "Batch 6 started...\n",
      "Epoch 1/20\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 11.1292 - auc_6: 0.4884WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 9.8903 - auc_6: 0.4870 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.9315 - auc_6: 0.5102 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.0092 - auc_6: 0.5496 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8389 - auc_6: 0.6335 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7544 - auc_6: 0.6500 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7268 - auc_6: 0.6491 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7066 - auc_6: 0.6523 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.7121 - auc_6: 0.6539 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7032 - auc_6: 0.6471 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6752 - auc_6: 0.6739 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6595 - auc_6: 0.6816 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6904 - auc_6: 0.6539 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6744 - auc_6: 0.6714 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6965 - auc_6: 0.6606 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6487 - auc_6: 0.6891 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6765 - auc_6: 0.6690 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6884 - auc_6: 0.6576 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6711 - auc_6: 0.6721 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7108 - auc_6: 0.6474 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6399 - auc_6: 0.6990 - val_loss: 0.0000e+00 - val_auc_6: 0.0000e+00\n",
      "Batch 7 started...\n",
      "Epoch 1/20\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 4.8027 - auc_7: 0.5236WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 14ms/step - loss: 4.7055 - auc_7: 0.5236 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.6448 - auc_7: 0.5470 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.9603 - auc_7: 0.5577 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.8589 - auc_7: 0.5626 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7824 - auc_7: 0.5877 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7581 - auc_7: 0.5987 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7266 - auc_7: 0.6140 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7164 - auc_7: 0.6360 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8071 - auc_7: 0.5909 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6930 - auc_7: 0.6534 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6907 - auc_7: 0.6547 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6806 - auc_7: 0.6509 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6697 - auc_7: 0.6650 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.7609 - auc_7: 0.6272 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6709 - auc_7: 0.6725 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6776 - auc_7: 0.6570 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6713 - auc_7: 0.6674 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6936 - auc_7: 0.6528 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7212 - auc_7: 0.6334 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7032 - auc_7: 0.6488 - val_loss: 0.0000e+00 - val_auc_7: 0.0000e+00\n",
      "Batch 8 started...\n",
      "Epoch 1/20\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 16.5071 - auc_8: 0.4928WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 14.0767 - auc_8: 0.4911 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 2.0041 - auc_8: 0.5639 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1332 - auc_8: 0.6086 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.9495 - auc_8: 0.6414 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8952 - auc_8: 0.6351 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8679 - auc_8: 0.6395 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8201 - auc_8: 0.6427 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8237 - auc_8: 0.6340 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.8062 - auc_8: 0.6290 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8016 - auc_8: 0.6305 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7303 - auc_8: 0.6522 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7122 - auc_8: 0.6568 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7381 - auc_8: 0.6426 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7429 - auc_8: 0.6361 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6994 - auc_8: 0.6540 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6832 - auc_8: 0.6549 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6611 - auc_8: 0.6724 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7297 - auc_8: 0.6325 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7148 - auc_8: 0.6311 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7142 - auc_8: 0.6347 - val_loss: 0.0000e+00 - val_auc_8: 0.0000e+00\n",
      "Batch 9 started...\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - ETA: 0s - loss: 4.3222 - auc_9: 0.4567WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 17ms/step - loss: 4.3222 - auc_9: 0.4567 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.0894 - auc_9: 0.4365 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.4583 - auc_9: 0.4997 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.0485 - auc_9: 0.5386 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.8491 - auc_9: 0.5839 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7787 - auc_9: 0.6106 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7239 - auc_9: 0.6392 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7160 - auc_9: 0.6426 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7723 - auc_9: 0.6211 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6869 - auc_9: 0.6632 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6783 - auc_9: 0.6640 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6664 - auc_9: 0.6741 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6343 - auc_9: 0.6988 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7703 - auc_9: 0.6228 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6735 - auc_9: 0.6708 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6438 - auc_9: 0.6910 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6652 - auc_9: 0.6775 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6765 - auc_9: 0.6693 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6547 - auc_9: 0.6795 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6748 - auc_9: 0.6683 - val_loss: 0.0000e+00 - val_auc_9: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "kfold = 10\n",
    "\n",
    "folds = StratifiedKFold(n_splits=kfold)\n",
    "\n",
    "val = np.zeros(X_nonTest.shape[0])\n",
    "models_deep1 = []\n",
    "for fold_index, (train_index, val_index) in enumerate(folds.split(X_nonTest,y_nonTest)):\n",
    "    print('Batch {} started...'.format(fold_index))\n",
    "    gc.collect()\n",
    "\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_nonTest.iloc[train_index]\n",
    "    )\n",
    "    model1 = create_model1()\n",
    "    result = model1.fit(X_nonTest.iloc[train_index],y_nonTest.iloc[train_index],\n",
    "            batch_size=128, epochs=20, verbose = 1,\n",
    "            validation_data = [(X_nonTest.iloc[val_index],y_nonTest.iloc[val_index])],\n",
    "            sample_weight= classes_weights\n",
    "            )\n",
    "    models_deep1.append(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.90      0.83       604\n",
      "        True       0.52      0.29      0.37       223\n",
      "\n",
      "    accuracy                           0.74       827\n",
      "   macro avg       0.65      0.60      0.60       827\n",
      "weighted avg       0.70      0.74      0.71       827\n",
      "\n",
      "0.5952432215721795\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모델1의 결과입니다.\n",
    "pred = np.zeros(df_test.shape[0])\n",
    "for model in models_deep1:\n",
    "    pred += model.predict(X_test)[:,0] / folds.n_splits\n",
    "    # predict_classes=np.argmax(predict_prob, axis=1)\n",
    "    # pred += model.predict_proba(df_test.drop(columns=target))[:,1]/folds.n_splits\n",
    "df_pred = pd.DataFrame(pred, columns = [target])\n",
    "print(classification_report(pred > 0.5, df_test[target]))\n",
    "auc_score_d1 = roc_auc_score(pred > 0.5, df_test[target])\n",
    "print(auc_score_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 모델은 노드를 (15 * 3)씩 가지는 은닉층 두개 model을 만듭니다.\n",
    "def create_model2():\n",
    "    model_deep = Sequential()\n",
    "    model_deep.add(Dense(15 * 3, activation='relu'))\n",
    "    model_deep.add(Dense(15 * 3, activation='relu'))\n",
    "    model_deep.add(Dense(1, activation='sigmoid'))\n",
    "    model_deep.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[AUC()])\n",
    "    return model_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 started...\n",
      "Epoch 1/20\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 4.3221 - auc_10: 0.5109WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 3.9623 - auc_10: 0.5108 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.5844 - auc_10: 0.5570 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.0488 - auc_10: 0.5998 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.9120 - auc_10: 0.6032 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8605 - auc_10: 0.6016 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7642 - auc_10: 0.6251 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7054 - auc_10: 0.6484 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6820 - auc_10: 0.6673 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7747 - auc_10: 0.6235 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7774 - auc_10: 0.6369 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6904 - auc_10: 0.6669 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6864 - auc_10: 0.6694 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6698 - auc_10: 0.6729 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6544 - auc_10: 0.6829 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7410 - auc_10: 0.6434 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6704 - auc_10: 0.6728 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6865 - auc_10: 0.6573 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7545 - auc_10: 0.6484 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6608 - auc_10: 0.6799 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6374 - auc_10: 0.6976 - val_loss: 0.0000e+00 - val_auc_10: 0.0000e+00\n",
      "Batch 1 started...\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - ETA: 0s - loss: 4.2447 - auc_11: 0.5103WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 16ms/step - loss: 4.2447 - auc_11: 0.5103 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.2528 - auc_11: 0.5290 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8351 - auc_11: 0.5665 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7708 - auc_11: 0.6146 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7133 - auc_11: 0.6399 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6962 - auc_11: 0.6335 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7037 - auc_11: 0.6381 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6791 - auc_11: 0.6545 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6711 - auc_11: 0.6524 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6735 - auc_11: 0.6542 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6809 - auc_11: 0.6573 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7384 - auc_11: 0.6253 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6610 - auc_11: 0.6681 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6650 - auc_11: 0.6594 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6876 - auc_11: 0.6421 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7193 - auc_11: 0.6312 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6392 - auc_11: 0.6902 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6725 - auc_11: 0.6543 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6837 - auc_11: 0.6365 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6526 - auc_11: 0.6710 - val_loss: 0.0000e+00 - val_auc_11: 0.0000e+00\n",
      "Batch 2 started...\n",
      "Epoch 1/20\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 2.7384 - auc_12: 0.5448WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 2.7179 - auc_12: 0.5452 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.2624 - auc_12: 0.5305 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8391 - auc_12: 0.5853 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8234 - auc_12: 0.5869 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7044 - auc_12: 0.6276 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6848 - auc_12: 0.6317 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6839 - auc_12: 0.6395 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7108 - auc_12: 0.6109 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7194 - auc_12: 0.6179 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6878 - auc_12: 0.6403 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6870 - auc_12: 0.6412 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6828 - auc_12: 0.6503 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6532 - auc_12: 0.6709 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6683 - auc_12: 0.6505 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6772 - auc_12: 0.6501 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6487 - auc_12: 0.6748 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6588 - auc_12: 0.6630 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6843 - auc_12: 0.6531 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6982 - auc_12: 0.6424 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6493 - auc_12: 0.6746 - val_loss: 0.0000e+00 - val_auc_12: 0.0000e+00\n",
      "Batch 3 started...\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - ETA: 0s - loss: 17.7650 - auc_13: 0.4851WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 16ms/step - loss: 17.7650 - auc_13: 0.4851 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.9630 - auc_13: 0.4271 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.2648 - auc_13: 0.4850 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.9636 - auc_13: 0.4768 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8116 - auc_13: 0.5120 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7341 - auc_13: 0.5635 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7062 - auc_13: 0.6041 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6988 - auc_13: 0.6071 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7383 - auc_13: 0.6084 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7684 - auc_13: 0.5865 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6996 - auc_13: 0.6300 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6748 - auc_13: 0.6651 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6728 - auc_13: 0.6534 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6807 - auc_13: 0.6472 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6875 - auc_13: 0.6270 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6562 - auc_13: 0.6671 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6487 - auc_13: 0.6760 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6668 - auc_13: 0.6594 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6679 - auc_13: 0.6599 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.6422 - auc_13: 0.6849 - val_loss: 0.0000e+00 - val_auc_13: 0.0000e+00\n",
      "Batch 4 started...\n",
      "Epoch 1/20\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 2.5961 - auc_14: 0.5381WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 17ms/step - loss: 2.4972 - auc_14: 0.5395 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8268 - auc_14: 0.5678 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7148 - auc_14: 0.6025 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7205 - auc_14: 0.6021 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6886 - auc_14: 0.6281 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6723 - auc_14: 0.6465 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6745 - auc_14: 0.6441 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6810 - auc_14: 0.6277 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6987 - auc_14: 0.6266 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6639 - auc_14: 0.6518 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6671 - auc_14: 0.6543 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.6867 - auc_14: 0.6495 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7097 - auc_14: 0.6222 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6961 - auc_14: 0.6213 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6546 - auc_14: 0.6613 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6439 - auc_14: 0.6806 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6465 - auc_14: 0.6694 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6539 - auc_14: 0.6639 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6379 - auc_14: 0.6828 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6363 - auc_14: 0.6884 - val_loss: 0.0000e+00 - val_auc_14: 0.0000e+00\n",
      "Batch 5 started...\n",
      "Epoch 1/20\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 5.7937 - auc_15: 0.5074WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 5.0912 - auc_15: 0.5067 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.1370 - auc_15: 0.5435 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.7937 - auc_15: 0.6112 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7497 - auc_15: 0.6262 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7240 - auc_15: 0.6380 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7029 - auc_15: 0.6444 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6866 - auc_15: 0.6579 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6914 - auc_15: 0.6415 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7326 - auc_15: 0.6252 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7451 - auc_15: 0.6276 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7119 - auc_15: 0.6391 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6804 - auc_15: 0.6642 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6955 - auc_15: 0.6502 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7082 - auc_15: 0.6386 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.7126 - auc_15: 0.6341 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6622 - auc_15: 0.6680 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6583 - auc_15: 0.6685 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6750 - auc_15: 0.6527 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6550 - auc_15: 0.6695 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6472 - auc_15: 0.6774 - val_loss: 0.0000e+00 - val_auc_15: 0.0000e+00\n",
      "Batch 6 started...\n",
      "Epoch 1/20\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 2.3505 - auc_16: 0.5573WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 2.2072 - auc_16: 0.5520 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8661 - auc_16: 0.6161 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7312 - auc_16: 0.6269 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7070 - auc_16: 0.6370 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7014 - auc_16: 0.6286 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6912 - auc_16: 0.6413 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6755 - auc_16: 0.6487 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6774 - auc_16: 0.6487 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6942 - auc_16: 0.6219 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6906 - auc_16: 0.6361 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6532 - auc_16: 0.6701 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6579 - auc_16: 0.6583 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6652 - auc_16: 0.6578 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6714 - auc_16: 0.6535 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6510 - auc_16: 0.6701 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6680 - auc_16: 0.6508 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6526 - auc_16: 0.6680 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7019 - auc_16: 0.6214 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6745 - auc_16: 0.6472 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6420 - auc_16: 0.6814 - val_loss: 0.0000e+00 - val_auc_16: 0.0000e+00\n",
      "Batch 7 started...\n",
      "Epoch 1/20\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 2.3658 - auc_17: 0.4499WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 20ms/step - loss: 2.2424 - auc_17: 0.4478 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.2327 - auc_17: 0.4547 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.0214 - auc_17: 0.5080 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9248 - auc_17: 0.5458 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.8333 - auc_17: 0.5746 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8227 - auc_17: 0.5617 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7391 - auc_17: 0.6005 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7105 - auc_17: 0.6239 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7840 - auc_17: 0.5959 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7162 - auc_17: 0.6313 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6742 - auc_17: 0.6629 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6936 - auc_17: 0.6403 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6699 - auc_17: 0.6621 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7962 - auc_17: 0.6160 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6780 - auc_17: 0.6655 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6579 - auc_17: 0.6742 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6655 - auc_17: 0.6673 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7072 - auc_17: 0.6489 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7260 - auc_17: 0.6322 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7064 - auc_17: 0.6408 - val_loss: 0.0000e+00 - val_auc_17: 0.0000e+00\n",
      "Batch 8 started...\n",
      "Epoch 1/20\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.6152 - auc_18: 0.4835WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 15ms/step - loss: 1.5888 - auc_18: 0.4809 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9900 - auc_18: 0.5245 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8726 - auc_18: 0.5549 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8517 - auc_18: 0.5988 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7958 - auc_18: 0.6115 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7729 - auc_18: 0.5994 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7401 - auc_18: 0.6148 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7273 - auc_18: 0.6315 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8327 - auc_18: 0.5947 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7795 - auc_18: 0.6044 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7049 - auc_18: 0.6435 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7058 - auc_18: 0.6338 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6870 - auc_18: 0.6555 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8217 - auc_18: 0.5940 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7070 - auc_18: 0.6334 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6785 - auc_18: 0.6491 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7100 - auc_18: 0.6359 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7647 - auc_18: 0.6162 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6925 - auc_18: 0.6370 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6699 - auc_18: 0.6605 - val_loss: 0.0000e+00 - val_auc_18: 0.0000e+00\n",
      "Batch 9 started...\n",
      "Epoch 1/20\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 2.2914 - auc_19: 0.4980WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 2.2811 - auc_19: 0.4992 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0035 - auc_19: 0.5459 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.7239 - auc_19: 0.6332 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6794 - auc_19: 0.6673 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7045 - auc_19: 0.6523 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6821 - auc_19: 0.6612 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6642 - auc_19: 0.6753 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6555 - auc_19: 0.6832 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6824 - auc_19: 0.6534 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6700 - auc_19: 0.6664 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6616 - auc_19: 0.6724 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6638 - auc_19: 0.6703 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6406 - auc_19: 0.6976 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7361 - auc_19: 0.6226 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6621 - auc_19: 0.6728 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6514 - auc_19: 0.6826 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6757 - auc_19: 0.6619 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6910 - auc_19: 0.6538 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6382 - auc_19: 0.6953 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6598 - auc_19: 0.6748 - val_loss: 0.0000e+00 - val_auc_19: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "kfold = 10\n",
    "\n",
    "folds = StratifiedKFold(n_splits=kfold)\n",
    "\n",
    "val = np.zeros(X_nonTest.shape[0])\n",
    "models_deep2 = []\n",
    "for fold_index, (train_index, val_index) in enumerate(folds.split(X_nonTest,y_nonTest)):\n",
    "    print('Batch {} started...'.format(fold_index))\n",
    "    gc.collect()\n",
    "\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_nonTest.iloc[train_index]\n",
    "    )\n",
    "    model = create_model2()\n",
    "    result = model.fit(X_nonTest.iloc[train_index],y_nonTest.iloc[train_index],\n",
    "            batch_size=128, epochs=20, verbose = 1,\n",
    "            validation_data = [(X_nonTest.iloc[val_index],y_nonTest.iloc[val_index])],\n",
    "            sample_weight= classes_weights\n",
    "            )\n",
    "    models_deep2.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.89      0.84       622\n",
      "        True       0.46      0.28      0.35       205\n",
      "\n",
      "    accuracy                           0.74       827\n",
      "   macro avg       0.63      0.59      0.59       827\n",
      "weighted avg       0.71      0.74      0.72       827\n",
      "\n",
      "0.5868010352129245\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모델2의 결과입니다.\n",
    "pred = np.zeros(df_test.shape[0])\n",
    "for model in models_deep2:\n",
    "    pred += model.predict(X_test)[:,0] / folds.n_splits\n",
    "    # predict_classes=np.argmax(predict_prob, axis=1)\n",
    "    # pred += model.predict_proba(df_test.drop(columns=target))[:,1]/folds.n_splits\n",
    "df_pred = pd.DataFrame(pred, columns = [target])\n",
    "print(classification_report(pred > 0.5, df_test[target]))\n",
    "auc_score_d2 = roc_auc_score(pred > 0.5, df_test[target])\n",
    "print(auc_score_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세번째 모델은 노드를 (15 * 2)씩 가지는 은닉층 세개 model을 만듭니다.\n",
    "def create_model3():\n",
    "    model_deep = Sequential()\n",
    "    model_deep.add(Dense(15 * 2, activation='relu'))\n",
    "    model_deep.add(Dense(15 * 2, activation='relu'))\n",
    "    model_deep.add(Dense(15 * 2, activation='relu'))\n",
    "    model_deep.add(Dense(1, activation='sigmoid'))\n",
    "    model_deep.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[AUC()])\n",
    "    return model_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 started...\n",
      "Epoch 1/20\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.5551 - auc_20: 0.5261WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 14ms/step - loss: 1.5559 - auc_20: 0.5229 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1134 - auc_20: 0.5681 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8556 - auc_20: 0.5888 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8145 - auc_20: 0.5864 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7427 - auc_20: 0.6100 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7295 - auc_20: 0.6205 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6916 - auc_20: 0.6402 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7479 - auc_20: 0.6176 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.8523 - auc_20: 0.5956 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.7264 - auc_20: 0.6443 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6704 - auc_20: 0.6682 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6787 - auc_20: 0.6656 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6970 - auc_20: 0.6515 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6575 - auc_20: 0.6793 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7487 - auc_20: 0.6451 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7107 - auc_20: 0.6383 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6871 - auc_20: 0.6550 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7744 - auc_20: 0.6321 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6686 - auc_20: 0.6773 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6356 - auc_20: 0.6962 - val_loss: 0.0000e+00 - val_auc_20: 0.0000e+00\n",
      "Batch 1 started...\n",
      "Epoch 1/20\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 10.3060 - auc_21: 0.4960WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 19ms/step - loss: 8.7541 - auc_21: 0.5079 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.1255 - auc_21: 0.5747 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7939 - auc_21: 0.6038 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7190 - auc_21: 0.6280 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7000 - auc_21: 0.6336 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7007 - auc_21: 0.6294 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6844 - auc_21: 0.6403 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6905 - auc_21: 0.6349 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7077 - auc_21: 0.6124 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7152 - auc_21: 0.6232 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6899 - auc_21: 0.6233 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7404 - auc_21: 0.6119 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6999 - auc_21: 0.6241 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6848 - auc_21: 0.6385 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6672 - auc_21: 0.6473 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6612 - auc_21: 0.6559 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6729 - auc_21: 0.6417 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6655 - auc_21: 0.6451 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6750 - auc_21: 0.6414 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6619 - auc_21: 0.6469 - val_loss: 0.0000e+00 - val_auc_21: 0.0000e+00\n",
      "Batch 2 started...\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - ETA: 0s - loss: 21.9359 - auc_22: 0.4989WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 21.9359 - auc_22: 0.4989 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2036 - auc_22: 0.4914 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9659 - auc_22: 0.4880 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.7633 - auc_22: 0.5325 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7162 - auc_22: 0.5715 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6887 - auc_22: 0.5983 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6796 - auc_22: 0.6246 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6654 - auc_22: 0.6348 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6848 - auc_22: 0.6244 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.6652 - auc_22: 0.6478 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6541 - auc_22: 0.6602 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6717 - auc_22: 0.6493 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6632 - auc_22: 0.6548 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6663 - auc_22: 0.6397 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6567 - auc_22: 0.6537 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6479 - auc_22: 0.6703 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6479 - auc_22: 0.6685 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6674 - auc_22: 0.6437 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6625 - auc_22: 0.6496 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6522 - auc_22: 0.6654 - val_loss: 0.0000e+00 - val_auc_22: 0.0000e+00\n",
      "Batch 3 started...\n",
      "Epoch 1/20\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 3.9927 - auc_23: 0.4988WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 3.8437 - auc_23: 0.4982 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0495 - auc_23: 0.5367 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7615 - auc_23: 0.5511 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7081 - auc_23: 0.5756 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6885 - auc_23: 0.6022 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6838 - auc_23: 0.6045 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6714 - auc_23: 0.6239 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6635 - auc_23: 0.6360 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6786 - auc_23: 0.6134 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6885 - auc_23: 0.6081 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.6585 - auc_23: 0.6485 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7069 - auc_23: 0.6127 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6580 - auc_23: 0.6558 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6548 - auc_23: 0.6614 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6522 - auc_23: 0.6644 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6479 - auc_23: 0.6707 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6443 - auc_23: 0.6743 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6453 - auc_23: 0.6726 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6458 - auc_23: 0.6720 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6419 - auc_23: 0.6808 - val_loss: 0.0000e+00 - val_auc_23: 0.0000e+00\n",
      "Batch 4 started...\n",
      "Epoch 1/20\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 8.3108 - auc_24: 0.5117 WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 7.9505 - auc_24: 0.5106 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.4696 - auc_24: 0.5443 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9067 - auc_24: 0.5515 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.8008 - auc_24: 0.5622 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7040 - auc_24: 0.6168 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6791 - auc_24: 0.6441 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6677 - auc_24: 0.6565 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6740 - auc_24: 0.6422 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6964 - auc_24: 0.6296 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7220 - auc_24: 0.6128 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7006 - auc_24: 0.6233 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6797 - auc_24: 0.6592 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7039 - auc_24: 0.6288 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7047 - auc_24: 0.6250 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6824 - auc_24: 0.6342 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6482 - auc_24: 0.6783 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6526 - auc_24: 0.6658 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6773 - auc_24: 0.6414 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6560 - auc_24: 0.6648 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6451 - auc_24: 0.6810 - val_loss: 0.0000e+00 - val_auc_24: 0.0000e+00\n",
      "Batch 5 started...\n",
      "Epoch 1/20\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 16.2579 - auc_25: 0.5031WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 19ms/step - loss: 15.3436 - auc_25: 0.4962 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.3743 - auc_25: 0.4356 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0640 - auc_25: 0.4842 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7315 - auc_25: 0.5909 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7019 - auc_25: 0.5985 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6827 - auc_25: 0.6174 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6759 - auc_25: 0.6272 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6802 - auc_25: 0.6321 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6741 - auc_25: 0.6367 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6699 - auc_25: 0.6393 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6597 - auc_25: 0.6577 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.6789 - auc_25: 0.6324 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6644 - auc_25: 0.6502 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6490 - auc_25: 0.6751 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6464 - auc_25: 0.6722 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6665 - auc_25: 0.6535 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6636 - auc_25: 0.6572 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6443 - auc_25: 0.6775 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6458 - auc_25: 0.6737 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6395 - auc_25: 0.6879 - val_loss: 0.0000e+00 - val_auc_25: 0.0000e+00\n",
      "Batch 6 started...\n",
      "Epoch 1/20\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 5.5762 - auc_26: 0.5082WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 17ms/step - loss: 5.1452 - auc_26: 0.5075 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.9867 - auc_26: 0.5271 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.7407 - auc_26: 0.5618 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6795 - auc_26: 0.6234 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6527 - auc_26: 0.6620 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6601 - auc_26: 0.6543 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6429 - auc_26: 0.6760 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6583 - auc_26: 0.6613 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6510 - auc_26: 0.6656 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6501 - auc_26: 0.6751 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6863 - auc_26: 0.6525 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6543 - auc_26: 0.6630 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6340 - auc_26: 0.6956 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6586 - auc_26: 0.6612 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6301 - auc_26: 0.6953 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6442 - auc_26: 0.6824 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6375 - auc_26: 0.6877 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6400 - auc_26: 0.6880 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6329 - auc_26: 0.6926 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6294 - auc_26: 0.6988 - val_loss: 0.0000e+00 - val_auc_26: 0.0000e+00\n",
      "Batch 7 started...\n",
      "Epoch 1/20\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 3.2547 - auc_27: 0.5197WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 18ms/step - loss: 3.1277 - auc_27: 0.5245 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.8681 - auc_27: 0.5199 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.7322 - auc_27: 0.5371 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7115 - auc_27: 0.5430 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7026 - auc_27: 0.5623 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6989 - auc_27: 0.5633 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6830 - auc_27: 0.5890 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6842 - auc_27: 0.5950 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6718 - auc_27: 0.6179 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6683 - auc_27: 0.6244 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6815 - auc_27: 0.6053 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6717 - auc_27: 0.6277 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6582 - auc_27: 0.6503 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6560 - auc_27: 0.6531 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6498 - auc_27: 0.6616 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6574 - auc_27: 0.6501 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6657 - auc_27: 0.6382 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6490 - auc_27: 0.6695 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6580 - auc_27: 0.6492 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6550 - auc_27: 0.6520 - val_loss: 0.0000e+00 - val_auc_27: 0.0000e+00\n",
      "Batch 8 started...\n",
      "Epoch 1/20\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 3.3379 - auc_28: 0.4948WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 20ms/step - loss: 3.2085 - auc_28: 0.4900 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0623 - auc_28: 0.5026 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7942 - auc_28: 0.5068 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.7142 - auc_28: 0.5805 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6797 - auc_28: 0.6180 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6798 - auc_28: 0.6245 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6643 - auc_28: 0.6453 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6720 - auc_28: 0.6442 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6617 - auc_28: 0.6503 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6637 - auc_28: 0.6483 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6595 - auc_28: 0.6588 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6524 - auc_28: 0.6637 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6487 - auc_28: 0.6755 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6635 - auc_28: 0.6521 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6411 - auc_28: 0.6810 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6517 - auc_28: 0.6733 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6549 - auc_28: 0.6637 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6555 - auc_28: 0.6670 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6397 - auc_28: 0.6821 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.6383 - auc_28: 0.6821 - val_loss: 0.0000e+00 - val_auc_28: 0.0000e+00\n",
      "Batch 9 started...\n",
      "Epoch 1/20\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 2.1396 - auc_29: 0.5107WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 15) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>). Consider rewriting this model with the Functional API.\n",
      "24/24 [==============================] - 1s 20ms/step - loss: 2.0787 - auc_29: 0.5111 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.8187 - auc_29: 0.5897 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.7136 - auc_29: 0.6295 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.6798 - auc_29: 0.6476 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6699 - auc_29: 0.6483 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6525 - auc_29: 0.6722 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6557 - auc_29: 0.6661 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6581 - auc_29: 0.6653 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.6500 - auc_29: 0.6723 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6475 - auc_29: 0.6764 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6539 - auc_29: 0.6664 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6345 - auc_29: 0.6935 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6338 - auc_29: 0.6959 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6547 - auc_29: 0.6647 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6466 - auc_29: 0.6790 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6850 - auc_29: 0.6435 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6540 - auc_29: 0.6649 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6758 - auc_29: 0.6536 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.6280 - auc_29: 0.7030 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.6348 - auc_29: 0.6923 - val_loss: 0.0000e+00 - val_auc_29: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "kfold = 10\n",
    "\n",
    "folds = StratifiedKFold(n_splits=kfold)\n",
    "\n",
    "val = np.zeros(X_nonTest.shape[0])\n",
    "models_deep3 = []\n",
    "for fold_index, (train_index, val_index) in enumerate(folds.split(X_nonTest,y_nonTest)):\n",
    "    print('Batch {} started...'.format(fold_index))\n",
    "    gc.collect()\n",
    "\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_nonTest.iloc[train_index]\n",
    "    )\n",
    "    model = create_model3()\n",
    "    result = model.fit(X_nonTest.iloc[train_index],y_nonTest.iloc[train_index],\n",
    "            batch_size=128, epochs=20, verbose = 1,\n",
    "            validation_data = [(X_nonTest.iloc[val_index],y_nonTest.iloc[val_index])],\n",
    "            sample_weight= classes_weights\n",
    "            )\n",
    "    models_deep3.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.90      0.81       575\n",
      "        True       0.52      0.26      0.35       252\n",
      "\n",
      "    accuracy                           0.70       827\n",
      "   macro avg       0.63      0.58      0.58       827\n",
      "weighted avg       0.67      0.70      0.67       827\n",
      "\n",
      "0.5787784679089027\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모델3의 결과입니다.\n",
    "pred = np.zeros(df_test.shape[0])\n",
    "for model in models_deep3:\n",
    "    pred += model.predict(X_test)[:,0] / folds.n_splits\n",
    "    # predict_classes=np.argmax(predict_prob, axis=1)\n",
    "    # pred += model.predict_proba(df_test.drop(columns=target))[:,1]/folds.n_splits\n",
    "df_pred = pd.DataFrame(pred, columns = [target])\n",
    "print(classification_report(pred > 0.5, df_test[target]))\n",
    "auc_score_d3 = roc_auc_score(pred > 0.5, df_test[target])\n",
    "print(auc_score_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.font_manager as fm\n",
    "\n",
    "# # 설치된 폰트 출력\n",
    "# font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "# font_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(4)\n",
    "methods = ['xgboost', 'dl_layer1*90', 'dl_layer2*45', 'dl_layer3*30']\n",
    "values = [auc_score_b, auc_score_d1, auc_score_d2, auc_score_d3]\n",
    "# values = [100, 200, 300, 400]\n",
    "\n",
    "plt.rcParams['font.family'] = 'Gulim'\n",
    "\n",
    "plt.title('AUC 점수표')\n",
    "bar = plt.bar(x, values)\n",
    "plt.xticks(x, methods)\n",
    "\n",
    "for rect in bar:\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.5f' % height, ha='center', va='bottom', size = 12)\n",
    "\n",
    "plt.show() # ephoc 20회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"output_ephocs10.png\") # ephoc 10회"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 완성하지 못한 부분에 대하여 \"한계점과 추후 해결 방안을 알맞게 작성하였는가?\"\n",
    "- 완성하지 못한 부분은 특별히 없으나 굳이 고려하자면, AUC 점수가 너무 낮게 나온 점이 아닌가 생각합니다. 이것은 기본적으로 이전 전처리에서 일부 null값을 평균으로 적당히 넣은 부작용일 수도 있고(그런 전처리를 하는 소스를 본 기억이 있습니다.) 최초 값이 잘못되어 올라왔을 가능성도 있습니다. 아마 모델 자체로는, 패러미터를 더 다변화하여 서치를 진행하면 좋은 값을 찾을 수 있을 지도 모릅니다. 좋은 값이 나온 결과의 모델들을 참고할 필요가 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19bbaa17aaad8524ce9adc9eae37b3db085ea561884ef46a686ec198f374fe48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
